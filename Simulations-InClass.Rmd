---
title: "Simulations Pre-Class Project"
date: "Due March 13, 2017 at 5:00pm"
output:
  html_document


---

<style type="text/css">
.table {

    width: 80%;
    margin-left:10%; 
    margin-right:10%;
}
</style>
```{r,setup, echo=FALSE, cache=TRUE}
## numbers >= 10^5 will be denoted in scientific notation,
## and rounded to 2 digits
options(scipen = 3, digits = 3)
```




#Project Goals:


With this project we will simulate a famoues probability problem. This will not require knowledge of probability or statistics but only the logic to follow the steps in order to simulate this problem. This is one way to solve problems by using the computer. 

 1. **Gambler's Ruin**: Suppose you have a bankroll of $1000 and make bets of $100 on a fair game. By simulating the outcome directly for at most 5000 iterations of the game (or hands), estimate:
    a. the probability that you have "busted" (lost all your money) by the time you have placed your one hundredth bet. 
```{r}
set.seed(1)
play_n_rounds1 <- function(n, bankroll, bet, p=.5){ #here we simulate n rounds
cumsum <- 0
thisround <- 0
count <- 0
bank <- bankroll
roundsmatrix <- matrix(NA, 4, n, byrow=F) #initiallizing the values and matrix we will be using - row 1 will hold net gained/lost, row 2 will hold number of hands survived, and row 3 will hold current bankroll total, row 4 will say whether you went bust or not
  for(i in 1:n) { #want n many rounds
    if(cumsum == -bankroll) { #if your out of money, keep the ratio of your cumsum
      roundsmatrix[1,i] <- cumsum #should be negative bankroll
      roundsmatrix[2,i] <- count
      roundsmatrix[3,i] <- bank #should be zero
      roundsmatrix[4,i] <- bank #should be zero
    } else { #play again
      count <- i
      winloss <- rbinom(1,1,p)*2-1 #1 if positive, negative 1 if negative
      thisround <- winloss*bet #gives positive bet or negative bet (a win or a loss)
      
      cumsum <- cumsum + thisround #cumsum keeps a cumulative sum
      roundsmatrix[1,i] <- cumsum
      
      roundsmatrix[2,i] <- count
    
      bank <- bank + bet*winloss
      roundsmatrix[3, i] <- bank
      
      if(bank == 0) {roundsmatrix[4,i] <- 0}
      else (roundsmatrix[4,i] <- 1) #1 means you lived, 0 means you went bankrupt, called at end so it can capture going bankrupt on last hand
    }
      
  }
print(roundsmatrix)[,n] #prints out the whole matrix
}
play_n_rounds1(120, 1000,100) #testing the function, it looks good


simulate_survival <- function (sims, n, bankroll, bet, p=.5) {
  results <- matrix(NA, 4,sims, byrow=F) #going to make a matrix store the simulation results in
  for(i in 1:sims) {
    results[,i] <- play_n_rounds1(n, bankroll, bet, p) #column n in the output (end of the game) gets stored in the results for iteration i
  }
  return(results)
} 
simulate_survival(100,12, 1000,1000) #was just testing my function worked
 
p_win <- function(matrixrow) {print(mean(matrixrow))}
p_lose<- function(matrixrow) {print(1-mean(matrixrow))}


#we want to run a simulation with 5000 sims, n of 100, a bankroll of 1000, and a bet of 100, (and a p of 0.5)
p_lose(simulate_survival(5000, 100, 1000, 100)[4,]) #gave 0.3206

```
    b. the probability that you have busted by the time you have placed your five hundredth bet by simulating the outcome directly. 
```{r}
p_lose(simulate_survival(100, 500, 1000, 100)[4,]) #this is the same thing, we just changed n, gave output of about .6
    
```
    c. the mean time you go bust, given that you go bust within the first 5000 hands.
```{r}
library(dplyr) #run dplyr
#we could use the above function to do this, but its much faster to just make a function to specialize in this. The above is a bit slow since it does everything at once



play_n_rounds2 <- function(n, bankroll, bet, p=.5){ #play n rounds 2 will tell us how many rounds we survived ( with a maximum value of n)
cumsum <- 0
thisround <- 0
count <- 0
roundsmatrix <- matrix(NA, 2, n, byrow=F) #This time we will work with a 2 row matrix (one for the count)
  for(i in 1:n) { 
    if(cumsum == -bankroll/bet) { 
      roundsmatrix[1,i] <- cumsum
      roundsmatrix[2,i] <- count #if you've lost, the count stays the same, lets fill that in for every column thereafter
    } else { 
      count = i #set count as i (note we can't simply use i or we'd have an issue in the above if statement since it'd keep growing even if we ran out of bankroll)
      thisround <- rbinom(1,1,p)*2-1 
    cumsum <- cumsum + thisround 
    roundsmatrix[1,i] <- cumsum
    roundsmatrix[2,i] <- count}
  }
print(roundsmatrix[2,n]) #tells you how many rounds were survived
}
play_n_rounds2(12, 1000,500) #testing the function



simulate_bust_time <- function (sims, n, bankroll, bet, p=.5) { #this time it will store how many rounds were survived in the simulation, not this is very similar to simulate_survival
  results <- matrix(NA, 1,sims, byrow=F) 
  for(i in 1:sims) {
    results[1,i] <- play_n_rounds2(n, bankroll, bet, p) #calls rounds2 not rounds1
  } #now we need to remove anyone who didn't go bust
  for(i in 1:sims) {
    if(results[1,i] == n) {
      results[1,i] <- NA #set people who made it to the end as NA
    } #no else statement needed
  }
  return(results)
} 

mean(simulate_bust_time(500, 5000, 1000, 100), na.rm=T) #ran a simulation of 500 times looking at the average amount of time busters spent playing before they busted (looking only at those who busted within their first 5000 plays) - they started with 1000 and bet 100 per play. Mean was 509.8045
```
    d. the mean and variance of your bankroll after 100 hands (including busts).
```{r}
partd <- simulate_survival(100, 100, 1000, 100)
mean(partd[3,]) #1072 was the output
var(partd[3,]) #113349 was the output

```
    e. the mean and variance of your bankroll after 500 hands (including busts).
```{r}
parte <- simulate_survival(100,500, 1000,100) #100 simulations of 500 hands with 1000 starting bankroll and bets of 100
mean(parte[3,]) #gave 1060
var(parte[3,]) #gave 236162
    
```
 
Note: you *must* stop playing if your player has gone bust. How will you handle this in the `for` loop?

2. Repeat the previous problem with betting on black in American roulette, where the probability of winning on any spin is 18/38 for an even payout.
```{r}
#a answer:
p_lose(simulate_survival(5000, 100, 1000, 100, p=.18/38)[4,]) #.501

#b answer
p_lose(simulate_survival(5000, 500, 1000, 100, p=18/38)[4,]) #.9162

#c answer
mean(simulate_bust_time(5000, 5000, 1000, 100, p=18/38), na.rm=T) #207.78

#d answer
partd2 <- simulate_survival(5000, 100, 1000, 100)
mean(partd2[3,]) #592.16 was the output
var(partd2[3,]) #570020.5 was the output

#e answer
parte2 <- simulate_survival(5000,500, 1000,100) #100 simulations of 500 hands with 1000 starting bankroll and bets of 100
mean(parte2[3,]) #gave 166.32
var(parte2[3,]) #gave 401041.9

```

3. **Markov Chains**. Suppose you have a game where the probability of winning on your first hand is 48%; each time you win, that probability goes up by one percentage point for the next game (to a maximum of 100%, where it must stay), and each time you lose, it goes back down to 48%. Assume you cannot go bust and that the size of your wager is a constant $100.
    a. Is this a fair game? Simulate one hundred thousand sequential hands to determine the size of your return. Then repeat this simulation 99 more times to get a range of values to calculate the expectation.
```{r}
set.seed(1)
#build the markov function based off the gamblers_ruin function
markov <- function(bet, p, maxrun = 100000){
  n <- 0 #initialize count of hands
  prob <- p
  net <- 0 #net is your net winning/losing
  while (1 > 0) {
    probval <- rbinom(1,1,p) #if a 1, its a win
    if (probval == 1) { #if win game, add bet value to net value; and increase probability of winning by 1%
      net <- net + bet
      p <- p + 0.01
    }else { #if lose game, subtract bet value from net value; and return probability of winning back to original input (p)
      net <- net - bet
      p <- prob
    }
    n <- n + 1 #increase hand by 1
    if (n == maxrun) { #simulate 100,000 sequential hands
      break
      }
  }
  return(net) #return net value
}

markov(100,.48,maxrun=100)


winnings <- function(bet, p, sims, maxrun = 100000) {
size <- numeric() #initialize size vector, size will have how much we won on the round
for (i in 1:sims) { #simulate sims many times
  next_size <- markov(bet, p, maxrun = maxrun) #fill the size vector using the markov function
  size <- c(size, next_size)
}
return(size)
}
mean(winnings(100, 0.48, 100, maxrun =100000)) #calculate the mean size of returns
```
This is not a fair game because the mean size of my return is 0.
    b. Repeat this process but change the starting probability to a new value within 2% either way. Get the expected return after 100 repetitions. Keep exploring until you have a return value that is as fair as you can make it. Can you do this automatically?
```{r}
for (j in 1:20) { #loop to make process automatic, intend to have starting value between 46% and 50%
  size = numeric() #initialize size vector
  for(i in 1:100) { #simulate 100 times
    next_size <- markov(100, 0.46+0.002*j, maxrun=10000) #fill the size vector using the markov function
    size <- c(size, next_size)
  }
  if(mean(size) > 0) {
      print(j)
    }
}
#lowest j value is 15 so a probability of .49, could always repeat this to zero in closer

```
    c. Repeat again, keeping the initial probability at 48%, but this time change the probability increment to a value different from 1%. Get the expected return after 100 repetitions. Keep changing this value until you have a return value that is as fair as you can make it.
```{r}


markovinc <- function(bet, p,inc,  maxrun = 100000){
  n <- 0 
  prob <- p
  net <- 0 
  while (1 > 0) {
    probval <- runif(1) 
    if (probval <= p) { 
      net <- net + bet
      p <- p + inc #see that we put this here
    }else { 
      net <- net - bet
      p <- prob
    }
    n <- n + 1 
    if (n == maxrun) { 
      break
      }
  }
  return(net) 
}    




for (j in 1:20) { 
  size = numeric() 
  for(i in 1:100) { 
    next_size <- markovinc(100, 0.48, .01+j/1000, maxrun=10000) #fill the size vector using the markov function
    size <- c(size, next_size)
  }
  if(mean(size) > 0) {
      print(j)
    }
}
#getting a value of j=4 so at a p=0.484 we can expect to tip toward a winning odds (so a fair game should be close), again we could keep zooming in and getting more precise
```


4. Creating a Bootstrap function. There is a particular concept called [bootstrapping]
(https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) where we can easily create 95% confidence intervals, even for complex estimators.

The steps of this process are:

  a. Draw a sample, with replacement, from your data which is the same length of your data.
  b. Calculate the statistic of interest on this boostrap sample (ie mean, variance, regression,...)
  c. Peform steps 1:2 at least 1000 times over until you have a vector of your statistics. 
  d. The lower bound of a 95% CI will be the 0.025 percentile
  e. The upper bound of a 95% CI will be the 0.975 percentile

Make a function called `boot_ci` which calculates the 95% confidence interval in this manner. 
```{r}
boot_ci <- function(data, fun, iterations=1000, lowerci=0.025, upperci=0.975) { #needs a function and a dataset
samplestats <- c(NA, length = iterations) #initializing vector
  for(i in 1:iterations) { #loops through 1000 times
    tempsample <- sample(data, length(data), replace=T) #sampling with replacement
    samplestats[i] <- fun(tempsample) #takes a sample then takes the function of it (ex mean of it)
  }
lowerbound <- quantile(samplestats, probs=lowerci) #find the lower and upperbound of the estimates
upperbound <- quantile(samplestats, probs=upperci)

print(c(lowerbound, upperbound)) #print out our 95 ci by default, ci range for alternate inputs
}



testset <- c(1:100)
boot_ci(testset, mean)#testing
```

5. For problems 3b and 3c, you calculated a mean value. Because you saved these final results in a vector, use the bootstrap to estimate the variance of the return in each case for your final answer. Once you have these results, which game has the smaller variance in returns?